{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing using wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thank you all so very much .', 'Thank you to the Academy .', 'Thank you to all of you in this room .', 'I have to congratulate the other incredible nominee this year .', 'The Revenant wa the product of the tireless effort of an unbelievable cast and crew .', 'First off , to my brother in this endeavor , Mr. Tom Hardy .', 'Tom , your talent on screen can only be surpassed by your friendship off screen … thank you for creating a t ranscendent cinematic experience .', 'Thank you to everybody at Fox and New Regency … my entire team .', 'I have to thank everyone from the very onset of my career … To my parent ; none of this would be possible without you .', 'And to my friend , I love you dearly ; you know who you are .', \"And lastly , I just want to say this : Making The Revenant wa about man 's relationship to the natural world .\", 'A world that we collectively felt in 2015 a the hottest year in recorded history .', 'Our production needed to move to the southern tip of this planet just to be able to find snow .', 'Climate change is real , it is happening right now .', 'It is the most urgent threat facing our entire specie , and we need to work collectively together and stop procrastinating .', 'We need to support leader around the world who do not speak for the big polluter , but who speak for all of humanity , for the indigenous people of the world , for the billion and billion of underprivileged people out there who would be most affected by this .', 'For our child ’ s child , and for those people out there whose voice have been drownedout by the politics of greed .', 'I thank you all for this amazing award tonight .', 'Let u not take this planet for granted .', 'I do not take tonight for granted .', 'Thank you so very much .']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "with open('text.txt','r') as file:\n",
    "    paragraph = file.read()\n",
    "\n",
    "    sentences = nltk.sent_tokenize(paragraph)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Lemmatization\n",
    "    for i in range(len(sentences)):\n",
    "        words = nltk.word_tokenize(sentences[i])\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        sentences[i] = ' '.join(words)   \n",
    "        \n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
